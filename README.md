# Awesome-Collaborative-Perception-Papers
collaborative perception, v2x-communication aided autonomous driving

## Dataset
1. \[ISPRS 2021\] **Comap: a Synthetic Dataset for Collective Multi-Agent Perception of Autonomous Driving.**[[paper]](https://ui.adsabs.harvard.edu/abs/2021ISPAr43B2..255Y/abstract) [[data]](https://seafile.cloud.uni-hannover.de/d/1c52826e98d34c0399a4/)
2. \[RAL 2022\] **V2X-Sim: A Virtual Collaborative Perception Dataset for Autonomous Driving.** [[paper]](https://arxiv.org/abs/2202.08449) [[code]](https://github.com/ai4ce/V2X-Sim)
3. \[ICRA 2022\] **OPV2V: An Open Benchmark Dataset and Fusion Pipeline for
Perception with Vehicle-to-Vehicle Communication.** [[paper]](https://arxiv.org/pdf/2109.07644.pdf) [[code]](https://github.com/DerrickXuNu/OpenCOOD)
4. \[CVPR 2022\] **DAIR-V2X: A Large-Scale Dataset for Vehicle-Infrastructure Cooperative 3D Object Detection.** [[website]](https://thudair.baai.ac.cn/index) [[code]](https://github.com/AIR-THU/DAIR-V2X)

## Collaboration framework
1. \[ICRA 2020\] **Who2com: Collaborative Perception via Learnable Handshake Communication.** [[paper]](https://arxiv.org/abs/2003.09575) [[code]](https://github.com/GT-RIPL/MultiAgentPerception)
2. \[CVPR 2020\] **When2com: Multi-Agent Perception via Communication Graph Grouping.**[[paper]](https://arxiv.org/abs/2006.00176) [[code]](https://github.com/GT-RIPL/MultiAgentPerception)
3. \[ECCV 2020\] **V2VNet: Vehicle-to-Vehicle Communication for Joint Perception and Prediction.** [[paper]](https://arxiv.org/abs/2008.07519)
4. \[MobiCom 2021\] **EMP: Edge-assisted Multi-vehicle Perception.** [[paper]](https://xiaoshawnzhu.github.io/emp-mobicom21.pdf) [[code]](https://github.com/Shawnxm/EMP)
5. \[NeurIPS 2021\] **Learning distilled collaboration graph for multi-agent perception.** [[paper]](https://proceedings.neurips.cc/paper/2021/file/f702defbc67edb455949f46babab0c18-Paper.pdf) [[code]](https://github.com/ai4ce/DiscoNet)
6. \[CVPR 2022\] **COOPERNAUT: End-to-End Driving with Cooperative Perception for Networked Vehicles.** [[paper]](https://arxiv.org/abs/2205.02222) [[code]](https://github.com/UT-Austin-RPL/Coopernaut)
7. \[ECCV 2022\] **V2X-ViT: Vehicle-to-Everything Cooperative Perception with Vision Transformer.**[[paper]](https://arxiv.org/abs/2203.10638) [[code]](https://github.com/DerrickXuNu/v2x-vit)
8. \[arxiv\] **Model-Agnostic Multi-Agent Perception Framework.** [[paper]](https://arxiv.org/pdf/2203.13168.pdf)
9. \[arxiv\] **CoBEVT: Cooperative Bird's Eye View Semantic Segmentation with Sparse Transformers.** [[paper]](https://arxiv.org/abs/2207.02202)

## Robustness to localization error
1. \[CoRL 2020\] **Learning to Communicate and Correct Pose Errors.** [[paper]](https://arxiv.org/abs/2011.05289)
2. \[IROS 2021\] **Overcoming Obstructions via Bandwidth-Limited Multi-Agent Spatial Handshaking.**[[paper]](https://arxiv.org/abs/2107.00771)
3. \[RAL 2022\] **Keypoints-Based Deep Feature Fusion for Cooperative Vehicle Detection of Autonomous Driving.** [[paper]](https://arxiv.org/abs/2109.11615) [[code]](https://github.com/YuanYunshuang/FPV_RCNN.git)
4. \[ECCV 2022\] **V2X-ViT: Vehicle-to-Everything Cooperative Perception with Vision Transformer.** [[paper]](https://arxiv.org/abs/2203.10638) [[code]](https://github.com/DerrickXuNu/v2x-vit)

## Robustness to communication constraints
1. \[ECCV 2022\] **Latency-Aware Collaborative Perception.** [[paper]](https://arxiv.org/pdf/2207.08560.pdf)
